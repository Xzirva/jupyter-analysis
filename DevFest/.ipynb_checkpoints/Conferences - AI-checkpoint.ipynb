{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Take Over (Valeuriad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple autour de PACMAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hub.docker.com/r/valeuriad/pacman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valeuriad/devfest2018 (github)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problème de classification de la position (X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation de jeu de données aléatoires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbre de décision pour classifier les mouvements. Puis randomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle non generalisable. Non déterministe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problème de convergence (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN : 2 réseaux de neurones. Gen (images semblables) et Disc (Real or Fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your own Google Assistant persona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persona is the UX for Voice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checkout SSML library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow Mobile : très lourd et très consommateur (non présent sur la doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization, Freeze\n",
    "Convertir le modèle avec TOCO : outputfile, inputfile, format: tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Kit : Mobile Vision, GC API :  \n",
    "OCR, Detection de visages, Labels d'image, detection de repères"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terraform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provider. Topology : Ensemble de ressources déployées en mm temps. Un TFT : Etat (Ex: Machine virtuelles créées)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get state, Call APIs, Push state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terrafor arrive son propre langage: HCL (hashicorp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBjet de type variable: terraform.tfvars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "On peut créer des resources et des variables en déclarant les topologies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation Topologie Réseau : terraform plan : planifie le déploiement.\n",
    "terraform apply (réalise le déploiement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFState, Provider, TF-cli : \n",
    "1. Get res ids existing in tfstate\n",
    "2. Get data from provider from ids in tfstate\n",
    "Generate graph from code (what needs to be created / modified / deleted) and then apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projet Terraform : \n",
    "chaque package contient: variables topology output.\n",
    "Packages :\n",
    "01_network\n",
    "02 application A\n",
    "02 application B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notion de Data source :\n",
    "    Create resource with tags,\n",
    "    Get resource (already created) according the tags.\n",
    "    \n",
    "\n",
    "Sous Terraform c'est un object de type data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kotlin Coroutines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous computatoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation : Async/Await :  \n",
    "solutions to time consuming operation  \n",
    "1. Callbacks : Hard to read (?)\n",
    "2. Async/Await : function () async {\n",
    "    ...await\n",
    "}\n",
    "\n",
    "Threads and Coroutines\n",
    "Lightweight threads (?)\n",
    "\n",
    "coroutines can be suspended\n",
    "The main thread is blocked waiting for forked threads (normally)\n",
    "with coroutines the thread can process some others tasks while waiting for a coroutine response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning & JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning : pretrained model\n",
    "    Convert it to be tensorflow.js ready\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KubeFlow : TensorFlow on K8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainer de manière scalable et répétable  \n",
    "Utiliser des modèles de données entrainés dans docker en image.\n",
    "\n",
    "Agréger les services ML sur K8s\n",
    "\n",
    "Use native elements of \n",
    "Etendre l'API de k8s vers les modèles de machine learning.\n",
    "Basé sur JupyterHub\n",
    "KatLib\n",
    "SeldonIO : deploying models\n",
    "Data Pipeline (check out)\n",
    "KSonnet : composer les env (dev test prod). generates various manifests for k8s.\n",
    "\n",
    "Creation des ambassadeurs : un ingress par ambassadeur. TFHUB == JupyterHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed training : VMs, Network, Upload Code,\n",
    "TFReplicaSet... (check this out)\n",
    "Change hyperparams :\n",
    "- With Helm : packages manager de K8s. Create a helm chart : get learning rate. get tfjobs, construire la matrice des hyper params.\n",
    "Serve : (production deploy)\n",
    "with ksonnet\n",
    "nouveau composant tfserving\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Creation tfjob : training répétable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making roll outs :\n",
    "integrates well with Istio (check out)\n",
    "2 models : Faire de l'A/B testing.\n",
    "Monitoring with grafana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka Connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer une pipeline en 20 minutes:\n",
    "platform de streaming distribué"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applications de production de données\n",
    "Applications de stream : read/write\n",
    "Applicatons systèmes tiers (ES, Cassandra, etc...) Exemple : faire des backups sur S3 par exemple\n",
    "Kafka connect : Streamer des données en entrée et en sortie de kafka trés facilement.\n",
    "\n",
    "    Cluster de master et workers.\n",
    "    Scalabilité automatique.\n",
    "    embarque une API rest qui permet de démarrer le cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producer API\n",
    "Debezium connector  \n",
    "\n",
    "Clusters : Kafka zookeeper kafka connect  \n",
    "Connectors : dbz connector S3 connect   \n",
    "DB: mysql db\n",
    "    \n",
    "    \"Change data\" capture with debezium  \n",
    "    Execution des connectors par : Connector configuration :  \n",
    "        JSON :  \n",
    "        Tasks :  \n",
    "        Database config : ...  \n",
    " \n",
    " Cree de nombres topics un pour chaque connector  \n",
    " \n",
    " Update :  \n",
    "     response : { Before, After }  \n",
    "     \n",
    " S3 connector configuration : on peut préciser un partitionner.  \n",
    " \n",
    " Amazon Athena : SQL Queries on (un)structured data.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
